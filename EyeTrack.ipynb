{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b176e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701a00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibrate camera for accurate results\n",
    "def calibrate(frame, model_points, image_points):\n",
    "    focal_length = frame.shape[1]  #width\n",
    "    center = (frame.shape[1]/ 2, frame.shape[0]/ 2)\n",
    "    camera_matrix = np.array([[focal_length, 0, center[0]],\n",
    "                     [0, focal_length, center[1]], [0, 0, 1]], dtype= 'double')\n",
    "    dist_coeffs = np.zeros((4, 1))\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix,\n",
    "                                                        dist_coeffs, flags= cv2.SOLVEPNP_ITERATIVE)\n",
    "    return camera_matrix, dist_coeffs, success, rotation_vector, translation_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3217e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative= lambda landmark, shape: (int(landmark.x* shape[1]), int(landmark.y* shape[0]))\n",
    "relativeT= lambda landmark, shape: (int(landmark.x* shape[1]), int(landmark.y* shape[0]), 0)\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a8c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_EYE= [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "RIGHT_EYE= [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633891a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaze(frame, points):\n",
    "    #normalized to [-1, 1], format (x, y)\n",
    "    image_points = np.array([\n",
    "        relative(points.landmark[4], frame.shape),     #nose tip\n",
    "        relative(points.landmark[152], frame.shape),   #chin\n",
    "        relative(points.landmark[263], frame.shape),   #left eye left corner\n",
    "        relative(points.landmark[33], frame.shape),    #right eye right corner\n",
    "        relative(points.landmark[287], frame.shape),   #left mouth corner\n",
    "        relative(points.landmark[57], frame.shape)],   #right mouth corner\n",
    "         dtype= 'double')\n",
    "\n",
    "    #normalized to [-1, 1], format (x, y, 0)\n",
    "    image_points1 = np.array([\n",
    "        relativeT(points.landmark[4], frame.shape),\n",
    "        relativeT(points.landmark[152], frame.shape),\n",
    "        relativeT(points.landmark[263], frame.shape),\n",
    "        relativeT(points.landmark[33], frame.shape),\n",
    "        relativeT(points.landmark[287], frame.shape),\n",
    "        relativeT(points.landmark[57], frame.shape)],\n",
    "         dtype= 'double')\n",
    "    \n",
    "    #3D model points\n",
    "    model_points = np.array([\n",
    "        (0.0, 0.0, 0.0),         #nose tip\n",
    "        (0, -63.6, -12.5),       #chin\n",
    "        (-43.3, 32.7, -26),      #left eye left corner\n",
    "        (43.3, 32.7, -26),       #right eye right corner\n",
    "        (-28.9, -28.9, -24.1),   #left mouth corner\n",
    "        (28.9, -28.9, -24.1)])   #right mouth corner\n",
    "    \n",
    "    #3d model eye points- center of the eye ball\n",
    "    Eye_ball_center_right = np.array([[-29.05],[32.7],[-39.5]])\n",
    "    Eye_ball_center_left = np.array([[29.05],[32.7],[-39.5]])\n",
    "    \n",
    "    camera_matrix, dist_coeffs, success, rotation_vector, translation_vector= calibrate(frame, model_points, image_points)\n",
    "    \n",
    "    left_pupil = relative(points.landmark[468], frame.shape)\n",
    "    right_pupil = relative(points.landmark[473], frame.shape)\n",
    "    \n",
    "    _, transformation, _ = cv2.estimateAffine3D(image_points1, model_points)\n",
    "\n",
    "    if transformation is not None:\n",
    "        #project pupil image point into 3d world point \n",
    "        pupil_world_cord = transformation@ np.array([[left_pupil[0], left_pupil[1], 0, 1]]).T\n",
    "        pupil_world_right= transformation@ np.array([[right_pupil[0], right_pupil[1], 0, 1]]).T\n",
    "\n",
    "        #3D gaze point (25 is arbitrary for gaze distance)\n",
    "        S = Eye_ball_center_left+ (pupil_world_cord- Eye_ball_center_left)* 25\n",
    "        S_right= Eye_ball_center_right+ (pupil_world_right- Eye_ball_center_right)* 25\n",
    "\n",
    "        #project a 3D gaze direction onto the image plane\n",
    "        (eye_pupil2D, _) = cv2.projectPoints((int(S[0]), int(S[1]), int(S[2])), rotation_vector,\n",
    "                                             translation_vector, camera_matrix, dist_coeffs)\n",
    "        (eye_pupil2D_right, _)= cv2.projectPoints((int(S_right[0]), int(S_right[1]), int(S_right[2])), rotation_vector,\n",
    "                                                 translation_vector, camera_matrix, dist_coeffs)\n",
    "        \n",
    "        #project 3D head pose into the image plane\n",
    "        (head_pose, _) = cv2.projectPoints((int(pupil_world_cord[0]), int(pupil_world_cord[1]), int(65)),\n",
    "                                           rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "        (head_right, _)= cv2.projectPoints((int(pupil_world_right[0]), int(pupil_world_right[1]), int(65)),\n",
    "                                            rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "        \n",
    "        #correct gaze for head rotation\n",
    "        gaze_left= left_pupil+ (eye_pupil2D[0][0]- left_pupil)- (head_pose[0][0]- left_pupil)\n",
    "        gaze_right= right_pupil+ (eye_pupil2D_right[0][0]- right_pupil)- (head_right[0][0]- right_pupil)\n",
    "\n",
    "        #draw gaze line into screen\n",
    "        PUPIL= [[int(left_pupil[0]), int(left_pupil[1])], [int(right_pupil[0]), int(right_pupil[1])]]\n",
    "        GAZE= [[int(gaze_left[0]), int(gaze_left[1])], [int(gaze_right[0]), int(gaze_right[1])]]\n",
    "        cv2.line(frame, PUPIL[0], GAZE[0], (255, 255, 255), 4)\n",
    "        cv2.line(frame, PUPIL[1], GAZE[1], (255, 255, 255), 4)\n",
    "        \n",
    "        transformer = Normalizer().fit(PUPIL)\n",
    "        PUPIL= transformer.transform(PUPIL)\n",
    "        GAZE= transformer.transform(GAZE)\n",
    "        #print('Pupil'+ str(PUPIL)+ '\\n'+ 'Gaze'+ str(GAZE)+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27ca67e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDist(point1, point2):\n",
    "    x1, y1= point1\n",
    "    x2, y2= point2\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "def blinkRatio(image, landmarks, right_indices, left_indices):\n",
    "    #right eye\n",
    "    rh_right = landmarks[right_indices[0]]\n",
    "    rh_left = landmarks[right_indices[8]]\n",
    "    rv_top = landmarks[right_indices[12]]\n",
    "    rv_bottom = landmarks[right_indices[4]]\n",
    "    cv2.line(image, rh_right, rh_left, (0, 0, 0), 2)\n",
    "    cv2.line(image, rv_top, rv_bottom, (0, 0, 0), 2)\n",
    "\n",
    "    #left eye\n",
    "    lh_right = landmarks[left_indices[0]]\n",
    "    lh_left = landmarks[left_indices[8]]\n",
    "    lv_top = landmarks[left_indices[12]]\n",
    "    lv_bottom = landmarks[left_indices[4]]\n",
    "    cv2.line(image, lh_right, lh_left, (0, 0, 0), 2)\n",
    "    cv2.line(image, lv_top, lv_bottom, (0, 0, 0), 2)\n",
    "    \n",
    "    #find distance\n",
    "    rhDist= euclideanDist(rh_right, rh_left)\n",
    "    rvDist= euclideanDist(rv_top, rv_bottom)\n",
    "    lhDist= euclideanDist(lh_right, lh_left)\n",
    "    lvDist= euclideanDist(lv_top, lv_bottom)\n",
    "\n",
    "    if not rvDist or not lvDist:\n",
    "        return True\n",
    "    rightRatio = rhDist/ rvDist\n",
    "    leftRatio = lhDist/ lvDist\n",
    "    ratio= (rightRatio+ leftRatio)/ 2\n",
    "    return ratio> 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f9f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarksDetection(image, results):\n",
    "    height, width= image.shape[: 2]\n",
    "    mesh_coord= [(int(point.x* width), int(point.y* height)) for point in results.multi_face_landmarks[0].landmark]\n",
    "    return mesh_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8fe612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_track(image, results):\n",
    "    img_h, img_w, img_c= image.shape\n",
    "    face_2d= []\n",
    "    face_3d= []\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "        for idx, lm in enumerate(face_landmarks.landmark):\n",
    "            if idx== 33 or idx== 263 or idx== 1 or idx== 61 or idx== 291 or idx== 199:\n",
    "                if idx== 1:\n",
    "                    nose_2d= (lm.x* img_w, lm.y * img_h)\n",
    "                    nose_3d= (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "                x, y= int(lm.x* img_w), int(lm.y* img_h)\n",
    "                face_2d.append([x, y])\n",
    "                face_3d.append([x, y, lm.z])\n",
    "        \n",
    "        face_2d = np.array(face_2d, dtype=np.float64)\n",
    "        face_3d = np.array(face_3d, dtype=np.float64)\n",
    "        cam_matrix, dist_matrix, success, rot_vec, trans_vec= calibrate(image, face_3d, face_2d)\n",
    "        rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "        angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "        x = angles[0] * 360\n",
    "        y = angles[1] * 360\n",
    "        z = angles[2] * 360\n",
    "        if y< -10:\n",
    "            text= \"Looking Left\"\n",
    "        elif y> 10:\n",
    "            text= \"Looking Right\"\n",
    "        elif x< -10:\n",
    "            text= \"Looking Down\"\n",
    "        elif x> 10:\n",
    "            text= \"Looking Up\"\n",
    "        else:\n",
    "            text= \"Forward\"\n",
    "        nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\n",
    "        point1= (int(nose_2d[0]), int(nose_2d[1]))\n",
    "        point2= (int(nose_2d[0] + y * 10) , int(nose_2d[1] - x * 10))\n",
    "        cv2.line(image, point1, point2, (255, 255, 255), 3)\n",
    "        cv2.putText(image, text, [100, 140], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ddf711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "CCFRAME= 0\n",
    "frame_count= 0\n",
    "\n",
    "with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        CCFRAME+= 1\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = face.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            head_track(image, results)\n",
    "            frame_count+= 1\n",
    "            coord= landmarksDetection(image, results)\n",
    "            if blinkRatio(image, coord, RIGHT_EYE, LEFT_EYE):\n",
    "                cv2.putText(image, 'Closed Eyes', [100, 100], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            else:\n",
    "                gaze(image, results.multi_face_landmarks[0])\n",
    "\n",
    "        cv2.imshow('Output Window', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):          \n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ab521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
